{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "118UKH5bWCGa"
      },
      "source": [
        "<center><img src=\"https://em-content.zobj.net/thumbs/240/apple/325/artist_1f9d1-200d-1f3a8.png\" width=\"120\">\n",
        "</center>\n",
        "\n",
        "### <center>Use this notebook to run your text-to-image server</center>\n",
        "### <center> [DALL-E Playground Repository](https://github.com/saharmor/dalle-playground) </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS8LbaonYm3a"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MyO_o-lTQn2A"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/saharmor/dalle-playground.git &> /dev/null\n",
        "!pip install -r dalle-playground/backend/requirements.txt &> /dev/null\n",
        "!pip install diffusers[\"torch\"] &> /dev/null\n",
        "!pip install jax==0.3.25 jaxlib==0.3.25 flax==0.6.2 &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqF_iNGmmVIC"
      },
      "source": [
        "# Run the backend web server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qrRYWN7qTioY",
        "outputId": "e0aa6b26-bec7-410c-f16b-2dd8edf75b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-cf853ccabe29>:26: DeprecationWarning: setDaemon() is deprecated, set the daemon attribute instead\n",
            "  new_thread.setDaemon(True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Downloading cloudflared for Linux x86_64...\n",
            "Your url is: https://saharmor.github.io/dalle-playground/?backendUrl=https://leading-chance-street-geek.trycloudflare.com\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "2023-09-25 11:11:39.659162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "--> Starting the image generation server. This might take up to two minutes.\n",
            "Downloading (…)p16/model_index.json: 100% 511/511 [00:00<00:00, 2.92MB/s]\n",
            "unet/diffusion_pytorch_model.safetensors not found\n",
            "Fetching 12 files:   0% 0/12 [00:00<?, ?it/s]\n",
            "Downloading (…)_encoder/config.json: 100% 629/629 [00:00<00:00, 2.81MB/s]\n",
            "\n",
            "Downloading (…)tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.65MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 820/820 [00:00<00:00, 3.52MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)cheduler_config.json: 100% 340/340 [00:00<00:00, 2.03MB/s]\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 8.68MB/s]\n",
            "\n",
            "Downloading (…)edf/unet/config.json: 100% 905/905 [00:00<00:00, 5.53MB/s]\n",
            "\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 13.7MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)bedf/vae/config.json: 100% 607/607 [00:00<00:00, 3.08MB/s]\n",
            "\n",
            "\n",
            "Downloading pytorch_model.bin:   0% 0.00/681M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:   1% 10.5M/1.73G [00:00<00:20, 84.6MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:   2% 10.5M/681M [00:00<00:09, 72.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:   2% 41.9M/1.73G [00:00<00:09, 171MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:   6% 41.9M/681M [00:00<00:04, 154MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:   4% 73.4M/1.73G [00:00<00:08, 192MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   6% 10.5M/167M [00:00<00:01, 79.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:   9% 62.9M/681M [00:00<00:04, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  19% 31.5M/167M [00:00<00:01, 115MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:   5% 94.4M/1.73G [00:00<00:10, 155MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  12% 83.9M/681M [00:00<00:03, 154MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:   7% 115M/1.73G [00:00<00:10, 159MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  31% 52.4M/167M [00:00<00:00, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  15% 105M/681M [00:00<00:03, 158MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:   8% 136M/1.73G [00:00<00:09, 161MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  44% 73.4M/167M [00:00<00:00, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  18% 126M/681M [00:00<00:04, 111MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:   9% 157M/1.73G [00:01<00:16, 95.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  56% 94.4M/167M [00:01<00:00, 78.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  22% 147M/681M [00:01<00:05, 89.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  10% 178M/1.73G [00:01<00:15, 103MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  69% 115M/167M [00:01<00:00, 88.3MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  12% 199M/1.73G [00:01<00:16, 94.6MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  25% 168M/681M [00:01<00:06, 85.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  81% 136M/167M [00:01<00:00, 85.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  26% 178M/681M [00:01<00:06, 76.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  88% 147M/167M [00:01<00:00, 74.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  13% 220M/1.73G [00:01<00:17, 87.4MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  28% 189M/681M [00:01<00:06, 78.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  94% 157M/167M [00:01<00:00, 78.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  13% 231M/1.73G [00:02<00:17, 87.4MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  29% 199M/681M [00:02<00:05, 80.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin: 100% 167M/167M [00:01<00:00, 86.2MB/s]\n",
            "\n",
            "\n",
            "Downloading pytorch_model.bin:  31% 210M/681M [00:02<00:05, 85.1MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  15% 262M/1.73G [00:02<00:14, 100MB/s] \u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  34% 231M/681M [00:02<00:04, 101MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  16% 283M/1.73G [00:02<00:12, 113MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  37% 252M/681M [00:02<00:03, 112MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  18% 304M/1.73G [00:02<00:11, 121MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  40% 273M/681M [00:02<00:03, 121MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  19% 325M/1.73G [00:02<00:11, 127MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  43% 294M/681M [00:02<00:02, 130MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  20% 346M/1.73G [00:02<00:10, 130MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  46% 315M/681M [00:02<00:02, 126MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  21% 367M/1.73G [00:03<00:10, 126MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  49% 336M/681M [00:03<00:02, 126MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  22% 388M/1.73G [00:03<00:10, 123MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  52% 357M/681M [00:03<00:02, 125MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  24% 409M/1.73G [00:03<00:10, 123MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  55% 377M/681M [00:03<00:02, 122MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  25% 430M/1.73G [00:03<00:10, 129MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  59% 398M/681M [00:03<00:02, 125MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  26% 451M/1.73G [00:03<00:10, 126MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  62% 419M/681M [00:03<00:02, 126MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  27% 472M/1.73G [00:03<00:09, 129MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  65% 440M/681M [00:03<00:01, 126MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  28% 493M/1.73G [00:04<00:09, 126MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  68% 461M/681M [00:04<00:01, 126MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  30% 514M/1.73G [00:04<00:09, 122MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  71% 482M/681M [00:04<00:01, 123MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  31% 535M/1.73G [00:04<00:09, 123MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  74% 503M/681M [00:04<00:01, 124MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  32% 556M/1.73G [00:04<00:09, 125MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  77% 524M/681M [00:04<00:01, 125MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  33% 577M/1.73G [00:04<00:09, 125MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  80% 545M/681M [00:04<00:01, 128MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  35% 598M/1.73G [00:04<00:08, 128MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  83% 566M/681M [00:04<00:00, 122MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  36% 619M/1.73G [00:05<00:09, 123MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  86% 587M/681M [00:05<00:00, 127MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  37% 640M/1.73G [00:05<00:08, 126MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  89% 608M/681M [00:05<00:00, 127MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  38% 661M/1.73G [00:05<00:08, 124MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  92% 629M/681M [00:05<00:00, 126MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  39% 682M/1.73G [00:05<00:08, 127MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  95% 650M/681M [00:05<00:00, 122MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  41% 703M/1.73G [00:05<00:08, 122MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  99% 671M/681M [00:05<00:00, 111MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin: 100% 681M/681M [00:06<00:00, 113MB/s]\n",
            "Fetching 12 files:  33% 4/12 [00:06<00:15,  1.97s/it]\n",
            "Downloading (…)on_pytorch_model.bin:  43% 744M/1.73G [00:06<00:09, 108MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  44% 765M/1.73G [00:06<00:08, 119MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  46% 797M/1.73G [00:06<00:06, 145MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  47% 818M/1.73G [00:06<00:05, 155MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  48% 839M/1.73G [00:06<00:05, 155MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  50% 870M/1.73G [00:06<00:04, 182MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  52% 902M/1.73G [00:07<00:04, 206MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  54% 933M/1.73G [00:07<00:03, 203MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  56% 965M/1.73G [00:07<00:03, 202MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  58% 996M/1.73G [00:07<00:03, 211MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  59% 1.03G/1.73G [00:07<00:03, 225MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  61% 1.06G/1.73G [00:07<00:02, 236MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  63% 1.09G/1.73G [00:07<00:02, 248MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  65% 1.12G/1.73G [00:07<00:02, 256MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  67% 1.15G/1.73G [00:08<00:02, 254MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  68% 1.18G/1.73G [00:08<00:02, 257MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  70% 1.22G/1.73G [00:08<00:02, 255MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  72% 1.25G/1.73G [00:08<00:01, 255MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  74% 1.28G/1.73G [00:08<00:01, 251MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  76% 1.31G/1.73G [00:08<00:01, 251MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  77% 1.34G/1.73G [00:08<00:01, 252MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  79% 1.37G/1.73G [00:08<00:01, 248MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  81% 1.41G/1.73G [00:09<00:01, 253MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  83% 1.44G/1.73G [00:09<00:01, 253MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  85% 1.47G/1.73G [00:09<00:01, 256MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  87% 1.50G/1.73G [00:09<00:00, 256MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  88% 1.53G/1.73G [00:09<00:00, 250MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  90% 1.56G/1.73G [00:09<00:00, 247MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  92% 1.59G/1.73G [00:09<00:00, 252MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  94% 1.63G/1.73G [00:09<00:00, 256MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  96% 1.66G/1.73G [00:10<00:00, 254MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin:  97% 1.69G/1.73G [00:10<00:00, 249MB/s]\u001b[A\n",
            "Downloading (…)on_pytorch_model.bin: 100% 1.73G/1.73G [00:10<00:00, 167MB/s]\n",
            "Fetching 12 files: 100% 12/12 [00:11<00:00,  1.07it/s]\n",
            "Loading pipeline components...: 100% 5/5 [00:03<00:00,  1.50it/s]\n",
            "--> Image generation server is up and running!\n",
            " * Serving Flask app 'app' (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:8000\n",
            " * Running on http://172.28.0.12:8000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Sep/2023 11:12:16] \"OPTIONS / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Sep/2023 11:12:16] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Sep/2023 11:12:36] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
            "100% 10/10 [00:04<00:00,  2.40it/s]\n",
            "Created 3 images from text prompt [dog sitting on a plane and enjoying the view outside]\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Sep/2023 11:12:42] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cf853ccabe29>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcloudflared_startup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Your url is: https://saharmor.github.io/dalle-playground/?backendUrl={announce_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from threading import Thread, Event\n",
        "\n",
        "app_port = 8000\n",
        "announce_url = None\n",
        "cloudflared_startup = Event()\n",
        "\n",
        "def update_announce_url(url):\n",
        "    global announce_url\n",
        "    announce_url = url\n",
        "\n",
        "def start_cloudflared(port):\n",
        "  from flask_cloudflared import _run_cloudflared\n",
        "  try:\n",
        "    announce_url = _run_cloudflared(port, 8888)\n",
        "  except:\n",
        "    raise\n",
        "  finally:\n",
        "    update_announce_url(announce_url)\n",
        "    cloudflared_startup.set()\n",
        "\n",
        "def run_with_cloudflared(thread):\n",
        "    old_run = thread.run\n",
        "\n",
        "    def new_run(*args, **kwargs):\n",
        "        new_thread = Thread(target = start_cloudflared, args=(app_port, ))\n",
        "        new_thread.setDaemon(True)\n",
        "        new_thread.start()\n",
        "        old_run(*args, **kwargs)\n",
        "\n",
        "    thread.run = new_run\n",
        "\n",
        "def app():\n",
        "  !python dalle-playground/backend/app.py --port {app_port} --save_to_disk true --img_format jpeg --output_dir generations\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    t1 = Thread(target = app)\n",
        "    run_with_cloudflared(t1)\n",
        "    t1.start()\n",
        "    cloudflared_startup.wait()\n",
        "    print(f\"Your url is: https://saharmor.github.io/dalle-playground/?backendUrl={announce_url}\")\n",
        "    t1.join()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}